{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5753d7d-04ae-4b9a-8278-967bbf2a732c",
   "metadata": {},
   "source": [
    "Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f735f4b-2292-4cfa-acaa-2675d1701f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LinearRegressionScratch:\n",
    "    def __init__(self, learning_rate=0.01, n_iters=1000):\n",
    "        self.lr = learning_rate\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        # Gradient Descent\n",
    "        for _ in range(self.n_iters):\n",
    "            y_pred = np.dot(X, self.weights) + self.bias\n",
    "\n",
    "            # Compute gradients\n",
    "            dw = -(2/n_samples) * np.dot(X.T, (y - y_pred))\n",
    "            db = -(2/n_samples) * np.sum(y - y_pred)\n",
    "\n",
    "            # Update parameters\n",
    "            self.weights -= self.lr * dw\n",
    "            self.bias -= self.lr * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.weights) + self.bias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267ab1d2-237a-4d27-b528-e5df1bfdd7bb",
   "metadata": {},
   "source": [
    "Cost funciotn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6080b892-2d47-4648-8676-c187458694b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.111066660861643\n",
      "0.04070970665422571\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mse_cost(X: np.ndarray, y: np.ndarray, w: np.ndarray, b: float = 0.0) -> float:\n",
    "    \"\"\"\n",
    "    Mean Squared Error cost for linear regression.\n",
    "\n",
    "    X: shape (n_samples, n_features)\n",
    "    y: shape (n_samples,)\n",
    "    w: shape (n_features,)\n",
    "    b: scalar intercept\n",
    "    \"\"\"\n",
    "    y_pred = X @ w + b          # predictions\n",
    "    errors = y - y_pred\n",
    "    return np.mean(errors ** 2)  # MSE\n",
    "\n",
    "    # toy data: y â‰ˆ 2*x + 1 with small noise\n",
    "rng = np.random.default_rng(0)\n",
    "x = rng.uniform(-2, 2, size=50)\n",
    "X = x.reshape(-1, 1)            # (n_samples, 1)\n",
    "true_w, true_b = 2.0, 1.0\n",
    "y = true_w * x + true_b + rng.normal(0, 0.2, size=x.size)\n",
    "\n",
    "# try two parameter guesses\n",
    "w1, b1 = np.array([0.0]), 0.0\n",
    "w2, b2 = np.array([2.0]), 1.0\n",
    "\n",
    "print(mse_cost(X, y, w1, b1))   # larger cost (bad fit)\n",
    "print(mse_cost(X, y, w2, b2))   # smaller cost (good fit)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
